"""
æµ‹è¯•GLM4.5æ¨¡å‹é›†æˆ
éªŒè¯æ–°å¢çš„GLM4.5æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_glm_model():
    """æµ‹è¯•GLM4.5æ¨¡å‹åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•GLM4.5æ¨¡å‹é›†æˆ")
    print("="*50)
    
    try:
        from enhanced_llm_interface_v2 import EnhancedLLMInterfaceV2
        
        # åˆå§‹åŒ–LLMæ¥å£
        llm = EnhancedLLMInterfaceV2()
        
        # æ£€æŸ¥GLM APIå¯†é’¥
        glm_api_key = os.getenv('GLM_API_KEY')
        print(f"GLM APIå¯†é’¥: {'å·²è®¾ç½®' if glm_api_key else 'æœªè®¾ç½®'}")
        
        # è·å–å¯ç”¨æ¨¡å‹
        available_models = llm.list_available_models()
        
        print("\nå¯ç”¨æ¨¡å‹çŠ¶æ€:")
        for model_type, models in available_models.items():
            print(f"\n{model_type.upper()} æ¨¡å‹:")
            for key, info in models.items():
                status = "âœ… å¯ç”¨" if info['available'] else "âŒ ä¸å¯ç”¨"
                provider = info['provider']
                print(f"  - {key} ({provider}): {status}")
        
        # æµ‹è¯•GLM4.5æ¨¡å‹
        if 'glm4.5' in available_models['remote'] and available_models['remote']['glm4.5']['available']:
            print(f"\nğŸš€ æµ‹è¯•GLM4.5æ¨¡å‹...")
            
            # è®¾ç½®GLM4.5æ¨¡å‹
            if llm.set_model('glm4.5'):
                print("âœ… æˆåŠŸè®¾ç½®GLM4.5æ¨¡å‹")
                
                # æµ‹è¯•ç”Ÿæˆ
                test_prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
                print(f"æµ‹è¯•æç¤º: {test_prompt}")
                
                result = llm.generate(test_prompt, max_tokens=200, temperature=0.7)
                
                if not result.error:
                    print(f"âœ… GLM4.5ç”ŸæˆæˆåŠŸ:")
                    print(f"   æ¨¡å‹: {result.model_key}")
                    print(f"   ç±»å‹: {result.model_type}")
                    print(f"   æ—¶é—´: {result.generation_time:.2f}ç§’")
                    print(f"   å†…å®¹: {result.content[:100]}...")
                else:
                    print(f"âŒ GLM4.5ç”Ÿæˆå¤±è´¥: {result.error}")
            else:
                print("âŒ æ— æ³•è®¾ç½®GLM4.5æ¨¡å‹")
        else:
            print("âŒ GLM4.5æ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
        
        # æµ‹è¯•æ¨¡å‹åˆ‡æ¢
        print(f"\nğŸ”„ æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½...")
        
        # å°è¯•åˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å‹
        local_models = [key for key, info in available_models['local'].items() 
                       if info['available'] and info.get('installed', False)]
        
        if local_models:
            local_model = local_models[0]
            print(f"åˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å‹: {local_model}")
            
            if llm.set_model(local_model):
                print("âœ… æœ¬åœ°æ¨¡å‹åˆ‡æ¢æˆåŠŸ")
                
                # å†åˆ‡æ¢å›GLM4.5
                if available_models['remote']['glm4.5']['available']:
                    if llm.set_model('glm4.5'):
                        print("âœ… æˆåŠŸåˆ‡æ¢å›GLM4.5æ¨¡å‹")
                    else:
                        print("âŒ åˆ‡æ¢å›GLM4.5å¤±è´¥")
            else:
                print("âŒ æœ¬åœ°æ¨¡å‹åˆ‡æ¢å¤±è´¥")
        else:
            print("âš ï¸  æ²¡æœ‰å¯ç”¨çš„æœ¬åœ°æ¨¡å‹è¿›è¡Œåˆ‡æ¢æµ‹è¯•")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = llm.get_generation_stats()
        print(f"\nğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
        print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
        print(f"   æˆåŠŸè¯·æ±‚: {stats['successful_requests']}")
        print(f"   å¤±è´¥è¯·æ±‚: {stats['failed_requests']}")
        if stats['successful_requests'] > 0:
            print(f"   å¹³å‡æ—¶é—´: {stats['average_time']:.2f}ç§’")
            print(f"   æˆåŠŸç‡: {stats['success_rate']:.1%}")
        
        print("\nâœ… GLM4.5é›†æˆæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_environment_variables():
    """æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®"""
    print("ğŸ”§ æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®")
    print("="*50)
    
    env_vars = [
        ('MODELSCOPE_SDK_TOKEN', 'ModelScope APIå¯†é’¥'),
        ('GLM_API_KEY', 'GLM APIå¯†é’¥'),
        ('GOOGLE_API_KEY', 'Google APIå¯†é’¥'),
        ('OPENAI_API_KEY', 'OpenAI APIå¯†é’¥'),
        ('NEO4J_URL', 'Neo4jæ•°æ®åº“URL'),
        ('NEO4J_USERNAME', 'Neo4jç”¨æˆ·å'),
        ('NEO4J_PASSWORD', 'Neo4jå¯†ç ')
    ]
    
    for var_name, description in env_vars:
        value = os.getenv(var_name)
        if value:
            # éšè—æ•æ„Ÿä¿¡æ¯
            if 'key' in var_name.lower() or 'password' in var_name.lower():
                display_value = f"{value[:8]}...{value[-4:]}" if len(value) > 12 else "***"
            else:
                display_value = value
            print(f"âœ… {description}: {display_value}")
        else:
            print(f"âŒ {description}: æœªè®¾ç½®")
    
    print("\nâœ… ç¯å¢ƒå˜é‡æ£€æŸ¥å®Œæˆ")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ GLM4.5æ¨¡å‹é›†æˆéªŒè¯")
    print("="*60)
    
    # æµ‹è¯•ç¯å¢ƒå˜é‡
    test_environment_variables()
    print()
    
    # æµ‹è¯•GLMæ¨¡å‹
    test_glm_model()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("="*60)

if __name__ == "__main__":
    main()