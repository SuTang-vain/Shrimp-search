"""
å¢å¼ºçš„ç”¨æˆ·ç•Œé¢ V2 - æ”¯æŒæ¨¡å‹é€‰æ‹©å’Œç®¡ç†
"""

import os
import json
from typing import Dict, Any, List, Tuple, Optional
from enhanced_user_interface import EnhancedUserInterface

class EnhancedUserInterfaceV2(EnhancedUserInterface):
    """å¢å¼ºçš„ç”¨æˆ·ç•Œé¢V2 - æ·»åŠ æ¨¡å‹ç®¡ç†åŠŸèƒ½"""
    
    def __init__(self):
        super().__init__()
    
    def get_model_selection(self, available_models: Dict[str, Dict[str, Any]]) -> Optional[str]:
        """è·å–ç”¨æˆ·çš„æ¨¡å‹é€‰æ‹©"""
        print("\nğŸ¤– å¯ç”¨æ¨¡å‹é€‰æ‹©:")
        print("="*60)
        
        model_options = []
        index = 1
        
        # æ˜¾ç¤ºè¿œç¨‹æ¨¡å‹
        if 'remote' in available_models and available_models['remote']:
            print(f"\nğŸ“¡ è¿œç¨‹æ¨¡å‹ (ModelScope):")
            for key, info in available_models['remote'].items():
                status = "âœ… å¯ç”¨" if info['available'] else "âŒ éœ€è¦APIå¯†é’¥"
                print(f"  {index}. {key}")
                print(f"     æè¿°: {info['description']}")
                print(f"     çŠ¶æ€: {status}")
                model_options.append(key)
                index += 1
        
        # æ˜¾ç¤ºæœ¬åœ°æ¨¡å‹
        if 'local' in available_models and available_models['local']:
            print(f"\nğŸ’» æœ¬åœ°æ¨¡å‹ (Ollama):")
            for key, info in available_models['local'].items():
                if info['available']:
                    if info['installed']:
                        status = "âœ… å·²å®‰è£…"
                    else:
                        status = "â¬‡ï¸ å¯å®‰è£…"
                else:
                    status = "âŒ OllamaæœåŠ¡ä¸å¯ç”¨"
                
                print(f"  {index}. {key}")
                print(f"     æè¿°: {info['description']}")
                print(f"     çŠ¶æ€: {status}")
                model_options.append(key)
                index += 1
        
        if not model_options:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            return None
        
        print(f"\n0. è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹")
        print("q. è¿”å›ä¸Šçº§èœå•")
        
        while True:
            try:
                choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (0-{len(model_options)}, q): ").strip().lower()
                
                if choice == 'q':
                    return None
                elif choice == '0':
                    return 'auto'
                else:
                    choice_idx = int(choice) - 1
                    if 0 <= choice_idx < len(model_options):
                        selected_model = model_options[choice_idx]
                        print(f"å·²é€‰æ‹©æ¨¡å‹: {selected_model}")
                        return selected_model
                    else:
                        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æ•°å­—æˆ– 'q'")
    
    def display_model_status(self, status_info: Dict[str, Any]):
        """æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€ä¿¡æ¯"""
        print("\nğŸ“Š æ¨¡å‹çŠ¶æ€ä¿¡æ¯:")
        print("="*50)
        
        # å½“å‰æ¨¡å‹
        current_model = status_info.get('current_model')
        if current_model:
            print(f"å½“å‰æ¨¡å‹: {current_model['key']} ({current_model['provider']})")
            print(f"æ¨¡å‹ç±»å‹: {current_model['type']}")
            print(f"æ¨¡å‹åç§°: {current_model['name']}")
            print(f"æè¿°: {current_model['description']}")
        else:
            print("å½“å‰æ¨¡å‹: æœªè®¾ç½®")
        
        # APIçŠ¶æ€
        api_status = "âœ… å·²é…ç½®" if status_info.get('api_key_available') else "âŒ æœªé…ç½®"
        print(f"APIå¯†é’¥: {api_status}")
        
        # OllamaçŠ¶æ€
        ollama_status = "âœ… å¯ç”¨" if status_info.get('ollama_available') else "âŒ ä¸å¯ç”¨"
        ollama_models = status_info.get('ollama_models', 0)
        print(f"OllamaæœåŠ¡: {ollama_status} (å·²å®‰è£…æ¨¡å‹: {ollama_models}ä¸ª)")
        
        # ç”Ÿæˆç»Ÿè®¡
        gen_stats = status_info.get('generation_stats', {})
        if gen_stats.get('total_requests', 0) > 0:
            print(f"\nğŸ“ˆ ç”Ÿæˆç»Ÿè®¡:")
            print(f"  æ€»è¯·æ±‚æ•°: {gen_stats['total_requests']}")
            print(f"  æˆåŠŸè¯·æ±‚: {gen_stats['successful_requests']}")
            print(f"  å¤±è´¥è¯·æ±‚: {gen_stats['failed_requests']}")
            print(f"  æˆåŠŸç‡: {gen_stats.get('success_rate', 0):.1%}")
            print(f"  å¹³å‡å“åº”æ—¶é—´: {gen_stats.get('average_time', 0):.2f}ç§’")
            
            # æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
            model_usage = gen_stats.get('model_usage', {})
            if model_usage:
                print(f"  æ¨¡å‹ä½¿ç”¨æ¬¡æ•°:")
                for model, count in model_usage.items():
                    print(f"    {model}: {count}æ¬¡")
    
    def get_model_management_action(self) -> str:
        """è·å–æ¨¡å‹ç®¡ç†æ“ä½œ"""
        print("\nğŸ”§ æ¨¡å‹ç®¡ç†:")
        print("="*40)
        print("1. åˆ‡æ¢æ¨¡å‹")
        print("2. æµ‹è¯•å½“å‰æ¨¡å‹")
        print("3. æŸ¥çœ‹æ¨¡å‹çŠ¶æ€")
        print("4. æŸ¥çœ‹Ollamaæ¨¡å‹")
        print("5. å®‰è£…æœ¬åœ°æ¨¡å‹")
        print("6. åˆ é™¤æœ¬åœ°æ¨¡å‹")
        print("7. é‡ç½®ç»Ÿè®¡ä¿¡æ¯")
        print("8. è¿”å›ä¸»èœå•")
        
        while True:
            choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-8): ").strip()
            if choice in ['1', '2', '3', '4', '5', '6', '7', '8']:
                return {
                    '1': 'switch',
                    '2': 'test',
                    '3': 'status',
                    '4': 'list_ollama',
                    '5': 'install',
                    '6': 'delete',
                    '7': 'reset_stats',
                    '8': 'back'
                }[choice]
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def display_test_result(self, test_result: Dict[str, Any]):
        """æ˜¾ç¤ºæ¨¡å‹æµ‹è¯•ç»“æœ"""
        print("\nğŸ§ª æ¨¡å‹æµ‹è¯•ç»“æœ:")
        print("="*40)
        
        if test_result['success']:
            print("âœ… æµ‹è¯•æˆåŠŸ")
            print(f"æ¨¡å‹: {test_result['model_key']} ({test_result['model_type']})")
            print(f"å“åº”æ—¶é—´: {test_result['generation_time']:.2f}ç§’")
            print(f"å“åº”å†…å®¹: {test_result['response']}")
        else:
            print("âŒ æµ‹è¯•å¤±è´¥")
            if test_result.get('model_key'):
                print(f"æ¨¡å‹: {test_result['model_key']}")
            print(f"é”™è¯¯ä¿¡æ¯: {test_result['error']}")
    
    def display_ollama_models(self, models: List[Dict[str, Any]]):
        """æ˜¾ç¤ºOllamaæ¨¡å‹åˆ—è¡¨"""
        print("\nğŸ’» Ollamaå·²å®‰è£…æ¨¡å‹:")
        print("="*50)
        
        if not models:
            print("æ²¡æœ‰å·²å®‰è£…çš„æ¨¡å‹")
            return
        
        for i, model in enumerate(models, 1):
            size_mb = model.get('size', 0) / (1024 * 1024)
            print(f"{i}. {model['name']}")
            print(f"   å¤§å°: {size_mb:.1f}MB")
            if model.get('modified_at'):
                print(f"   ä¿®æ”¹æ—¶é—´: {model['modified_at']}")
    
    def get_model_name_input(self, prompt: str = "è¯·è¾“å…¥æ¨¡å‹åç§°") -> Optional[str]:
        """è·å–æ¨¡å‹åç§°è¾“å…¥"""
        model_name = input(f"{prompt}: ").strip()
        if not model_name:
            print("âŒ æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
            return None
        return model_name
    
    def confirm_action(self, action: str, target: str = "") -> bool:
        """ç¡®è®¤æ“ä½œ"""
        message = f"ç¡®è®¤{action}"
        if target:
            message += f" {target}"
        message += "? (y/N): "
        
        response = input(message).strip().lower()
        return response in ['y', 'yes', 'æ˜¯', 'Y']
    
    def display_operation_progress(self, operation: str, status: str):
        """æ˜¾ç¤ºæ“ä½œè¿›åº¦"""
        print(f"â³ {operation}: {status}")
    
    def display_operation_result(self, operation: str, success: bool, message: str = ""):
        """æ˜¾ç¤ºæ“ä½œç»“æœ"""
        if success:
            print(f"âœ… {operation}æˆåŠŸ")
        else:
            print(f"âŒ {operation}å¤±è´¥")
        
        if message:
            print(f"   {message}")
    
    def get_retrieval_mode_v2(self) -> str:
        """è·å–æ£€ç´¢æ¨¡å¼ - V2ç‰ˆæœ¬æ”¯æŒæ›´å¤šé€‰é¡¹"""
        print("\nğŸ” é€‰æ‹©æ£€ç´¢æ¨¡å¼:")
        print("="*40)
        print("1. å¿«é€Ÿæ£€ç´¢ - åŸºç¡€å‘é‡æ£€ç´¢")
        print("2. æ·±åº¦æ£€ç´¢ - æŸ¥è¯¢é‡å†™+HyDE+RRFèåˆ")
        print("3. ä¸»é¢˜æ£€ç´¢ - PDF+ç½‘é¡µç»¼åˆåˆ†æ")
        print("4. æ™ºèƒ½æ£€ç´¢ - è‡ªé€‚åº”é€‰æ‹©æœ€ä½³ç­–ç•¥")
        
        mode_map = {
            '1': 'å¿«é€Ÿæ£€ç´¢',
            '2': 'æ·±åº¦æ£€ç´¢', 
            '3': 'ä¸»é¢˜æ£€ç´¢',
            '4': 'æ™ºèƒ½æ£€ç´¢'
        }
        
        while True:
            choice = input("\nè¯·é€‰æ‹©æ£€ç´¢æ¨¡å¼ (1-4): ").strip()
            if choice in mode_map:
                selected_mode = mode_map[choice]
                print(f"å·²é€‰æ‹©: {selected_mode}")
                return selected_mode
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def display_model_comparison(self, comparison_data: Dict[str, Any]):
        """æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”"""
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
        print("="*60)
        
        for model_key, data in comparison_data.items():
            print(f"\n{model_key}:")
            print(f"  å¹³å‡å“åº”æ—¶é—´: {data.get('avg_time', 0):.2f}ç§’")
            print(f"  æˆåŠŸç‡: {data.get('success_rate', 0):.1%}")
            print(f"  ä½¿ç”¨æ¬¡æ•°: {data.get('usage_count', 0)}")
            print(f"  æ¨¡å‹ç±»å‹: {data.get('model_type', 'unknown')}")
    
    def get_generation_settings(self) -> Dict[str, Any]:
        """è·å–ç”Ÿæˆè®¾ç½®"""
        print("\nâš™ï¸ ç”Ÿæˆè®¾ç½®")
        print("æ˜¯å¦è‡ªå®šä¹‰ç”Ÿæˆå‚æ•°? (y/n): ", end="")
        
        choice = input().strip().lower()
        if choice != 'y':
            return {}
        
        settings = {}
        
        # æ¸©åº¦è®¾ç½®
        print("è®¾ç½®ç”Ÿæˆæ¸©åº¦ (0.0-1.0, é»˜è®¤0.7): ", end="")
        temp_input = input().strip()
        if temp_input:
            try:
                temp_value = float(temp_input)
                if 0.0 <= temp_value <= 1.0:
                    settings['temperature'] = temp_value
                else:
                    print("æ¸©åº¦å€¼åº”åœ¨0.0-1.0ä¹‹é—´ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            except ValueError:
                print("æ— æ•ˆæ¸©åº¦å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        
        # æœ€å¤§tokenè®¾ç½®
        print("è®¾ç½®æœ€å¤§tokenæ•° (100-2000, é»˜è®¤800): ", end="")
        token_input = input().strip()
        if token_input:
            try:
                token_value = int(token_input)
                if 100 <= token_value <= 2000:
                    settings['max_tokens'] = token_value
                else:
                    print("tokenæ•°åº”åœ¨100-2000ä¹‹é—´ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            except ValueError:
                print("æ— æ•ˆtokenæ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        
        return settings

    def display_query_result_v2(self, result: Dict[str, Any]):
        """æ˜¾ç¤ºæŸ¥è¯¢ç»“æœV2"""
        if 'error' in result:
            print(f"\nâŒ æŸ¥è¯¢å¤±è´¥: {result['error']}")
            return
        
        print(f"\nğŸ“‹ æŸ¥è¯¢ç»“æœ")
        print("="*60)
        
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        print(f"åŸå§‹é—®é¢˜: {result.get('original_query', 'N/A')}")
        print(f"æ£€ç´¢æ–¹æ³•: {result.get('retrieval_method', 'N/A')}")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        model_info = result.get('model_info', {})
        if model_info:
            print(f"ä½¿ç”¨æ¨¡å‹: {model_info.get('key', 'N/A')} ({model_info.get('type', 'N/A')})")
            print(f"ç”Ÿæˆæ—¶é—´: {model_info.get('generation_time', 0):.2f}ç§’")
        
        # æ˜¾ç¤ºæ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡
        retrieved_docs = result.get('retrieved_docs', [])
        if retrieved_docs:
            print(f"æ£€ç´¢æ–‡æ¡£: {len(retrieved_docs)} ä¸ª")
        
        # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
        final_answer = result.get('final_answer', '')
        if final_answer:
            print(f"\nğŸ’¡ ç­”æ¡ˆ:")
            print("-"*40)
            print(final_answer)
            print("-"*40)
        
        # æ˜¾ç¤ºé¢å¤–ä¿¡æ¯
        if 'rewritten_query' in result:
            print(f"\nğŸ”„ é‡å†™æŸ¥è¯¢: {result['rewritten_query']}")
        
        if 'web_research' in result:
            web_result = result['web_research']
            if web_result.get('success'):
                print(f"\nğŸŒ ç½‘é¡µç ”ç©¶: æˆåŠŸæ£€ç´¢ {len(web_result.get('results', []))} ä¸ªç½‘é¡µ")

    def get_advanced_settings(self) -> Dict[str, Any]:
        """è·å–é«˜çº§è®¾ç½®"""
        print("\nâš™ï¸ é«˜çº§è®¾ç½®:")
        print("="*30)
        
        settings = {}
        
        # æœ€å¤§ä»¤ç‰Œæ•°
        try:
            max_tokens = input("æœ€å¤§ä»¤ç‰Œæ•° (é»˜è®¤1000): ").strip()
            settings['max_tokens'] = int(max_tokens) if max_tokens else 1000
        except ValueError:
            settings['max_tokens'] = 1000
        
        # æ¸©åº¦å‚æ•°
        try:
            temperature = input("æ¸©åº¦å‚æ•° 0.0-1.0 (é»˜è®¤0.7): ").strip()
            temp_val = float(temperature) if temperature else 0.7
            settings['temperature'] = max(0.0, min(1.0, temp_val))
        except ValueError:
            settings['temperature'] = 0.7
        
        # æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º
        stream = input("å¯ç”¨æµå¼è¾“å‡º? (y/N): ").strip().lower()
        settings['stream'] = stream in ['y', 'yes', 'æ˜¯']
        
        return settings
    
    def display_generation_result(self, result: Any):
        """æ˜¾ç¤ºç”Ÿæˆç»“æœ - æ”¯æŒæ–°çš„ç»“æœæ ¼å¼"""
        if hasattr(result, 'error') and result.error:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {result.error}")
            return
        
        print("\nğŸ’¡ ç”Ÿæˆç»“æœ:")
        print("="*50)
        
        if hasattr(result, 'content'):
            print(result.content)
            print(f"\nğŸ“Š ç”Ÿæˆä¿¡æ¯:")
            print(f"  æ¨¡å‹: {getattr(result, 'model_key', 'unknown')}")
            print(f"  ç±»å‹: {getattr(result, 'model_type', 'unknown')}")
            print(f"  è€—æ—¶: {getattr(result, 'generation_time', 0):.2f}ç§’")
        else:
            # å…¼å®¹æ—§æ ¼å¼
            if isinstance(result, dict):
                if 'error' in result:
                    print(f"âŒ é”™è¯¯: {result['error']}")
                elif 'final_answer' in result:
                    print(result['final_answer'])
                    print(f"\nğŸ“Š æ£€ç´¢ä¿¡æ¯:")
                    print(f"  æ£€ç´¢æ–¹æ³•: {result.get('retrieval_method', 'unknown')}")
                    if 'retrieved_docs' in result:
                        print(f"  ç›¸å…³æ–‡æ¡£: {len(result['retrieved_docs'])}ä¸ª")
            else:
                print(str(result))