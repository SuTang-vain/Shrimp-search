"""
æ–‡æ¡£ç®¡ç†åŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¢å¼ºçš„æ–‡æ¡£é¢„å¤„ç†ç¼“å­˜ã€å¢é‡æ›´æ–°å’Œå¤šæ ¼å¼æ”¯æŒåŠŸèƒ½
"""

import os
import sys
from pathlib import Path
from enhanced_document_manager import EnhancedDocumentManager

def demo_document_formats():
    """æ¼”ç¤ºå¤šç§æ–‡æ¡£æ ¼å¼æ”¯æŒ"""
    print("ğŸ¯ æ¼”ç¤º1: å¤šç§æ–‡æ¡£æ ¼å¼æ”¯æŒ")
    print("="*60)
    
    manager = EnhancedDocumentManager(cache_dir="demo_cache")
    
    # æ˜¾ç¤ºæ”¯æŒçš„æ ¼å¼
    print("ğŸ“‹ æ”¯æŒçš„æ–‡æ¡£æ ¼å¼:")
    for fmt in manager.supported_formats.keys():
        print(f"  â€¢ {fmt}")
    
    print(f"\nâœ… æ–‡æ¡£ç®¡ç†å™¨æ”¯æŒ {len(manager.supported_formats)} ç§æ ¼å¼")

def demo_caching_system():
    """æ¼”ç¤ºç¼“å­˜ç³»ç»Ÿ"""
    print("\nğŸ¯ æ¼”ç¤º2: æ–‡æ¡£é¢„å¤„ç†ç¼“å­˜ç³»ç»Ÿ")
    print("="*60)
    
    manager = EnhancedDocumentManager(
        cache_dir="demo_cache",
        enable_cache=True,
        max_cache_size_mb=100
    )
    
    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    test_content = """
# æµ‹è¯•æ–‡æ¡£

è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºæ¼”ç¤ºç¼“å­˜åŠŸèƒ½ã€‚

## ç¬¬ä¸€ç« 
è¿™é‡Œæ˜¯ç¬¬ä¸€ç« çš„å†…å®¹ã€‚

## ç¬¬äºŒç« 
è¿™é‡Œæ˜¯ç¬¬äºŒç« çš„å†…å®¹ã€‚

### 2.1 å°èŠ‚
è¿™æ˜¯ä¸€ä¸ªå°èŠ‚çš„å†…å®¹ã€‚

## æ€»ç»“
è¿™æ˜¯æ–‡æ¡£çš„æ€»ç»“éƒ¨åˆ†ã€‚
    """
    
    test_file = "test_document.md"
    with open(test_file, 'w', encoding='utf-8') as f:
        f.write(test_content)
    
    try:
        print("ğŸ“„ é¦–æ¬¡å¤„ç†æ–‡æ¡£...")
        chunks1 = manager.process_document(test_file)
        print(f"âœ… å¤„ç†å®Œæˆ: {len(chunks1)} ä¸ªæ–‡æ¡£å—")
        
        print("\nğŸ“„ å†æ¬¡å¤„ç†åŒä¸€æ–‡æ¡£ (åº”ä½¿ç”¨ç¼“å­˜)...")
        chunks2 = manager.process_document(test_file)
        print(f"âœ… å¤„ç†å®Œæˆ: {len(chunks2)} ä¸ªæ–‡æ¡£å—")
        
        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        cache_stats = manager.get_cache_stats()
        print(f"\nğŸ’¾ ç¼“å­˜ç»Ÿè®¡:")
        print(f"  â€¢ ç¼“å­˜æ–‡æ¡£æ•°: {cache_stats['cached_documents']}")
        print(f"  â€¢ ç¼“å­˜å¤§å°: {cache_stats['total_size_mb']:.2f}MB")
        print(f"  â€¢ ç¼“å­˜ä½¿ç”¨ç‡: {cache_stats['cache_usage_percent']:.1f}%")
        
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_file):
            os.unlink(test_file)

def demo_batch_processing():
    """æ¼”ç¤ºæ‰¹é‡æ–‡æ¡£å¤„ç†"""
    print("\nğŸ¯ æ¼”ç¤º3: æ‰¹é‡æ–‡æ¡£å¤„ç†")
    print("="*60)
    
    manager = EnhancedDocumentManager(cache_dir="demo_cache")
    
    # åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡æ¡£
    test_files = []
    for i in range(3):
        filename = f"test_doc_{i+1}.txt"
        content = f"""
æ–‡æ¡£ {i+1}

è¿™æ˜¯ç¬¬ {i+1} ä¸ªæµ‹è¯•æ–‡æ¡£ã€‚

å†…å®¹åŒ…æ‹¬:
- é¡¹ç›® 1
- é¡¹ç›® 2
- é¡¹ç›® 3

ç»“æŸã€‚
        """
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        test_files.append(filename)
    
    try:
        print(f"ğŸ“š æ‰¹é‡å¤„ç† {len(test_files)} ä¸ªæ–‡æ¡£...")
        results = manager.batch_process_documents(test_files, max_workers=2)
        
        total_chunks = sum(len(chunks) for chunks in results.values())
        print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: æ€»å…± {total_chunks} ä¸ªæ–‡æ¡£å—")
        
        for file_path, chunks in results.items():
            print(f"  â€¢ {file_path}: {len(chunks)} ä¸ªå—")
            
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        for file_path in test_files:
            if os.path.exists(file_path):
                os.unlink(file_path)

def demo_incremental_updates():
    """æ¼”ç¤ºå¢é‡æ›´æ–°åŠŸèƒ½"""
    print("\nğŸ¯ æ¼”ç¤º4: å¢é‡æ–‡æ¡£æ›´æ–°")
    print("="*60)
    
    from Enhanced_Interactive_Multimodal_RAG import EnhancedRAGSystem, LLMConfig
    from dotenv import load_dotenv
    
    load_dotenv()
    api_key = os.getenv('MODELSCOPE_SDK_TOKEN')
    
    if not api_key:
        print("âš ï¸ æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œè·³è¿‡å¢é‡æ›´æ–°æ¼”ç¤º")
        return
    
    try:
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        config = LLMConfig(
            model_name="Qwen/Qwen2.5-72B-Instruct",
            max_tokens=500,
            temperature=0.7
        )
        
        rag_system = EnhancedRAGSystem(
            api_key=api_key,
            config=config,
            enable_performance_monitoring=False
        )
        
        # åˆ›å»ºåˆå§‹æ–‡æ¡£
        doc1_content = """
# åˆå§‹æ–‡æ¡£

è¿™æ˜¯çŸ¥è¯†åº“ä¸­çš„ç¬¬ä¸€ä¸ªæ–‡æ¡£ã€‚

## ä¸»è¦å†…å®¹
- æ¦‚å¿µA
- æ¦‚å¿µB
- æ¦‚å¿µC
        """
        
        doc1_file = "initial_doc.md"
        with open(doc1_file, 'w', encoding='utf-8') as f:
            f.write(doc1_content)
        
        print("ğŸ“š è®¾ç½®åˆå§‹çŸ¥è¯†åº“...")
        rag_system.setup_knowledge_base([doc1_file], "path")
        print(f"âœ… åˆå§‹çŸ¥è¯†åº“åŒ…å« {len(rag_system.current_sources)} ä¸ªæ–‡æ¡£")
        
        # åˆ›å»ºæ–°æ–‡æ¡£
        doc2_content = """
# æ–°å¢æ–‡æ¡£

è¿™æ˜¯åæ¥æ·»åŠ çš„æ–‡æ¡£ã€‚

## æ–°å†…å®¹
- æ¦‚å¿µD
- æ¦‚å¿µE
- æ¦‚å¿µF
        """
        
        doc2_file = "new_doc.md"
        with open(doc2_file, 'w', encoding='utf-8') as f:
            f.write(doc2_content)
        
        print("\nğŸ“„ å¢é‡æ·»åŠ æ–°æ–‡æ¡£...")
        success = rag_system.add_documents_to_knowledge_base([doc2_file], "path")
        
        if success:
            print(f"âœ… å¢é‡æ›´æ–°æˆåŠŸ! çŸ¥è¯†åº“ç°åŒ…å« {len(rag_system.current_sources)} ä¸ªæ–‡æ¡£")
            
            # æµ‹è¯•æŸ¥è¯¢
            print("\nğŸ” æµ‹è¯•æŸ¥è¯¢...")
            results = rag_system.enhanced_query("æ¦‚å¿µDæ˜¯ä»€ä¹ˆï¼Ÿ", "å¿«é€Ÿæ£€ç´¢")
            
            if 'error' not in results:
                print("âœ… æŸ¥è¯¢æˆåŠŸï¼Œæ–°æ–‡æ¡£å†…å®¹å·²å¯æ£€ç´¢")
            else:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {results['error']}")
        
        # æ¸…ç†æ–‡ä»¶
        for file_path in [doc1_file, doc2_file]:
            if os.path.exists(file_path):
                os.unlink(file_path)
                
    except Exception as e:
        print(f"âŒ å¢é‡æ›´æ–°æ¼”ç¤ºå¤±è´¥: {e}")

def demo_cache_management():
    """æ¼”ç¤ºç¼“å­˜ç®¡ç†åŠŸèƒ½"""
    print("\nğŸ¯ æ¼”ç¤º5: ç¼“å­˜ç®¡ç†åŠŸèƒ½")
    print("="*60)
    
    manager = EnhancedDocumentManager(
        cache_dir="demo_cache",
        max_cache_size_mb=1  # è®¾ç½®å¾ˆå°çš„ç¼“å­˜é™åˆ¶ç”¨äºæ¼”ç¤º
    )
    
    # åˆ›å»ºå¤šä¸ªæ–‡æ¡£æ¥å¡«æ»¡ç¼“å­˜
    test_files = []
    for i in range(5):
        filename = f"cache_test_{i+1}.txt"
        # åˆ›å»ºè¾ƒå¤§çš„å†…å®¹
        content = f"æ–‡æ¡£ {i+1}\n" + "è¿™æ˜¯æµ‹è¯•å†…å®¹ã€‚\n" * 100
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        test_files.append(filename)
    
    try:
        print("ğŸ“š å¤„ç†å¤šä¸ªæ–‡æ¡£ä»¥æµ‹è¯•ç¼“å­˜ç®¡ç†...")
        
        for i, file_path in enumerate(test_files):
            print(f"\nğŸ“„ å¤„ç†æ–‡æ¡£ {i+1}: {file_path}")
            chunks = manager.process_document(file_path)
            
            cache_stats = manager.get_cache_stats()
            print(f"  ç¼“å­˜ä½¿ç”¨: {cache_stats['cache_usage_percent']:.1f}%")
            
            if cache_stats['cache_usage_percent'] > 80:
                print("  ğŸ—‘ï¸ ç¼“å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œè‡ªåŠ¨æ¸…ç†ä¸­...")
        
        print("\nğŸ’¾ æœ€ç»ˆç¼“å­˜ç»Ÿè®¡:")
        final_stats = manager.get_cache_stats()
        for key, value in final_stats.items():
            print(f"  â€¢ {key}: {value}")
        
        # æ¼”ç¤ºæ‰‹åŠ¨æ¸…ç†ç¼“å­˜
        print("\nğŸ—‘ï¸ æ‰‹åŠ¨æ¸…ç†æ‰€æœ‰ç¼“å­˜...")
        manager.clear_cache()
        
        after_clear_stats = manager.get_cache_stats()
        print(f"âœ… æ¸…ç†åç¼“å­˜æ–‡æ¡£æ•°: {after_clear_stats['cached_documents']}")
        
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        for file_path in test_files:
            if os.path.exists(file_path):
                os.unlink(file_path)

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ æ–‡æ¡£ç®¡ç†åŠŸèƒ½æ¼”ç¤º")
    print("="*80)
    
    try:
        # æ¼”ç¤º1: å¤šç§æ–‡æ¡£æ ¼å¼æ”¯æŒ
        demo_document_formats()
        
        # æ¼”ç¤º2: ç¼“å­˜ç³»ç»Ÿ
        demo_caching_system()
        
        # æ¼”ç¤º3: æ‰¹é‡å¤„ç†
        demo_batch_processing()
        
        # æ¼”ç¤º4: å¢é‡æ›´æ–° (éœ€è¦APIå¯†é’¥)
        demo_incremental_updates()
        
        # æ¼”ç¤º5: ç¼“å­˜ç®¡ç†
        demo_cache_management()
        
        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    finally:
        # æ¸…ç†æ¼”ç¤ºç¼“å­˜ç›®å½•
        import shutil
        cache_dir = Path("demo_cache")
        if cache_dir.exists():
            shutil.rmtree(cache_dir)
            print("ğŸ—‘ï¸ æ¼”ç¤ºç¼“å­˜å·²æ¸…ç†")

if __name__ == "__main__":
    main()